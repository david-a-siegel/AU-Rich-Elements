{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import minimize,minimize_scalar, curve_fit\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load User-Defined Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "referenceDF = pd.read_csv('Data_To_Share/sequence_level_data_Jurkat.csv')\n",
    "referenceDF_logratio = pd.read_csv('Data_To_Share/sequence_level_data_Jurkat_T0T4_logRatios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the CXCL7 padding sequences have AREs -- we can account for these if desired...\n",
    "\n",
    "cxcl7_list = ['SUPV3L1|10:70968792-70968830','TRPT1|11:63991271-63991346','ART4|12:14982266-14982303','POLE2|14:50116899-50116969','NMRAL1|16:4511716-4511779','ADPRM|17:10614462-10614520','NUP85|17:73231775-73231829','PPP1R15A|19:49379231-49379294','PQLC3|2:11300834-11300874','FASTKD1|2:170386287-170386333','TFPI|2:188343337-188343401','YBEY|21:47717549-47717616','ALG1L|3:125648118-125648193','HELQ|4:84328529-84328604','TMEM171|5:72427558-72427617','IL4|5:132018280-132018347','PCDHA11|5:140251122-140251185','PCDHA12|5:140257437-140257474','GIN1|5:102423545-102423600','HLA-DQA1|6:32610542-32610561','CCDC132|7:92905660-92905721','NAPRT|8:144656955-144657006']\n",
    "CXCL7_ARE_list = []\n",
    "for region in referenceDF.region:\n",
    "    if region in cxcl7_list:\n",
    "        CXCL7_ARE_list.append(1)\n",
    "    else:\n",
    "        CXCL7_ARE_list.append(0)\n",
    "referenceDF['CXCL7_ARE']=CXCL7_ARE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cxcl7_list),sum(CXCL7_ARE_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Power of Different Categorizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a bunch of oligo ratios and different categories.  Do LOCO and for each category predict a mean.  See how well predictions correlate with left out oligos.  Iterate over all chromosomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARED Plus Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_number = []\n",
    "for region in referenceDF.region:\n",
    "    chrom_number.append(region.split('|')[1].split(':')[0])\n",
    "referenceDF['chrom_number']=chrom_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T0_GC_resid 0.12988807700915642\n",
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T4T0_GC_resid 0.30601023785419845\n",
      "motif_AREs_numbered_BakheetPlus ratios_T0_GC_resid 0.08862665534333984\n",
      "motif_AREs_numbered_BakheetPlus ratios_T4T0_GC_resid 0.2548912841693636\n"
     ]
    }
   ],
   "source": [
    "# Accounts for CXCL7:\n",
    "\n",
    "for are_category in ['parent_motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')&(referenceDF.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')&(referenceDF.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.nanmedian(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])\n",
    "        \n",
    "for are_category in ['motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.iscontrol==1)&(referenceDF.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.iscontrol==1)&(referenceDF.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.nanmedian(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: some of the correlations above are slightly different from published values due to exclusion of slightly different set of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make \"effective perfect length\" variable from length and registration:\n",
    "referenceDF['effective_perfect_length'] = referenceDF.ARE_registration_perfect + referenceDF.ARE_length_perfect\n",
    "\n",
    "\n",
    "# It helps to make a \"parent effective perfect length\" variable:\n",
    "referenceDF_byOligo = referenceDF.copy()\n",
    "referenceDF_byOligo.index = referenceDF_byOligo.ids\n",
    "parent_effective_perfect_length_list = []\n",
    "for parent_oligo in referenceDF_byOligo.parent_control_oligo:\n",
    "    if parent_oligo in referenceDF_byOligo.ids.values:\n",
    "        parent_effective_perfect_length_list.append(referenceDF_byOligo.loc[parent_oligo,'effective_perfect_length'])\n",
    "    else:\n",
    "        parent_effective_perfect_length_list.append(np.nan)\n",
    "referenceDF['parent_effective_perfect_length'] = parent_effective_perfect_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect_size_T0_GC_resid 0.15839698465117696\n",
      "effect_size_T4T0_GC_resid 0.3696980185478312\n",
      "ratios_T0_GC_resid 0.14078280483265623\n",
      "ratios_T4T0_GC_resid 0.3095853851658214\n"
     ]
    }
   ],
   "source": [
    "#Account for CXCL7:\n",
    "\n",
    "for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "#     are_category = 'parent_ARE'\n",
    "#     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "    test_predictions = []\n",
    "    test_actual = []\n",
    "    for chrom in referenceDF.chrom_number.unique():\n",
    "        train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')&(referenceDF.CXCL7_ARE==0)] #it had iscontrol==1 above\n",
    "        test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')&(referenceDF.CXCL7_ARE==0)]\n",
    "\n",
    "        train_df.index = train_df.ids\n",
    "        test_df.index = test_df.ids\n",
    "        \n",
    "        predictions_dict = {}\n",
    "        \n",
    "        for parent_effective_perfect_length in range(5,22):\n",
    "            predictions_dict[parent_effective_perfect_length]=np.mean(train_df[figure_of_merit][train_df.parent_effective_perfect_length==parent_effective_perfect_length])\n",
    "        \n",
    "        for parent_effective_perfect_length,test_fom in zip(test_df.parent_effective_perfect_length,test_df[figure_of_merit]):\n",
    "            if parent_effective_perfect_length<22:\n",
    "                if not pd.isnull(test_fom):\n",
    "                    test_predictions.append(predictions_dict[parent_effective_perfect_length])\n",
    "                    test_actual.append(test_fom)\n",
    "\n",
    "    print(figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])\n",
    "\n",
    "\n",
    "\n",
    "for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "#     are_category = 'parent_ARE'\n",
    "#     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "    test_predictions = []\n",
    "    test_actual = []\n",
    "    for chrom in referenceDF.chrom_number.unique():\n",
    "        train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.CXCL7_ARE==0)] #it had iscontrol==1 above\n",
    "        test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.CXCL7_ARE==0)]\n",
    "\n",
    "        train_df.index = train_df.ids\n",
    "        test_df.index = test_df.ids\n",
    "        \n",
    "        predictions_dict = {}\n",
    "        \n",
    "        for effective_perfect_length in range(5,22):\n",
    "            mask = train_df.effective_perfect_length==effective_perfect_length\n",
    "            mask = mask.fillna(False)\n",
    "            predictions_dict[effective_perfect_length]=np.mean(train_df[figure_of_merit][mask])\n",
    "        \n",
    "        for effective_perfect_length,test_fom in zip(test_df.effective_perfect_length,test_df[figure_of_merit]):\n",
    "            if not pd.isnull(effective_perfect_length):\n",
    "                if effective_perfect_length<22:\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[effective_perfect_length])\n",
    "                        test_actual.append(test_fom)\n",
    "\n",
    "    print(figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Effective Length Pentamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groups: 5, 6-9, 10-13, 14-17, 18-21 (effective length).  Add one for imperfect?\n",
    "david_groups_perfect = []\n",
    "for effective_perfect_length in referenceDF.effective_perfect_length:\n",
    "    if not pd.isnull(effective_perfect_length):\n",
    "        if effective_perfect_length<=5:\n",
    "            david_groups_perfect.append(1)\n",
    "        elif effective_perfect_length<=9:\n",
    "            david_groups_perfect.append(2)\n",
    "        elif effective_perfect_length<=13:\n",
    "            david_groups_perfect.append(3)\n",
    "        elif effective_perfect_length<=17:\n",
    "            david_groups_perfect.append(4)\n",
    "        elif effective_perfect_length<=22:\n",
    "            david_groups_perfect.append(5)\n",
    "        elif effective_perfect_length>22:\n",
    "            david_groups_perfect.append(6)\n",
    "        else:\n",
    "            david_groups_perfect.append(np.nan)\n",
    "    else:\n",
    "        david_groups_perfect.append(np.nan)\n",
    "referenceDF['david_groups_perfect']=david_groups_perfect\n",
    "\n",
    "parent_david_groups_perfect = []\n",
    "referenceDF_byOligo = referenceDF.copy()\n",
    "referenceDF_byOligo.index = referenceDF.ids\n",
    "for oligo,parent_oligo in zip(referenceDF.ids.values,referenceDF.parent_control_oligo.values):\n",
    "    if not pd.isnull(parent_oligo):\n",
    "        parent_david_groups_perfect.append(referenceDF_byOligo.loc[parent_oligo,'david_groups_perfect'])\n",
    "    else:\n",
    "        parent_david_groups_perfect.append(np.nan)\n",
    "        \n",
    "referenceDF['parent_david_groups_perfect']=parent_david_groups_perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_david_groups_perfect effect_size_T0_GC_resid 0.14972015078440315\n",
      "parent_david_groups_perfect effect_size_T4T0_GC_resid 0.3529200985582243\n",
      "david_groups_perfect ratios_T0_GC_resid 0.1149938185724824\n",
      "david_groups_perfect ratios_T4T0_GC_resid 0.29949281424547497\n"
     ]
    }
   ],
   "source": [
    "#Account for CXCL7\n",
    "\n",
    "for are_category in ['parent_david_groups_perfect']:\n",
    "    for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')&(referenceDF.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')&(referenceDF.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category > 1)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category>1)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])\n",
    "        \n",
    "for are_category in ['david_groups_perfect']:\n",
    "    for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.iscontrol==1)&(referenceDF.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.iscontrol==1)&(referenceDF.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category > 1)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category > 1)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann Whitney U Test For Significance of Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps to make a \"parent_ARE_length_perfect\" and a \"parent_ARE_registration_perfect\" variable:\n",
    "referenceDF_byOligo = referenceDF.copy()\n",
    "referenceDF_byOligo.index = referenceDF_byOligo.ids\n",
    "parent_ARE_length_perfect_list = []\n",
    "parent_ARE_registration_perfect_list = []\n",
    "for parent_oligo in referenceDF_byOligo.parent_control_oligo:\n",
    "    if parent_oligo in referenceDF_byOligo.ids.values:\n",
    "        parent_ARE_length_perfect_list.append(referenceDF_byOligo.loc[parent_oligo,'ARE_length_perfect'])\n",
    "        parent_ARE_registration_perfect_list.append(referenceDF_byOligo.loc[parent_oligo,'ARE_registration_perfect'])\n",
    "    else:\n",
    "        parent_ARE_length_perfect_list.append(np.nan)\n",
    "        parent_ARE_registration_perfect_list.append(np.nan)\n",
    "referenceDF['parent_ARE_length_perfect'] = parent_ARE_length_perfect_list\n",
    "referenceDF['parent_ARE_registration_perfect'] = parent_ARE_registration_perfect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T0_GC_resid 0.3371002781988618\n",
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T4T0_GC_resid 0.00421447853462852\n",
      "motif_AREs_numbered_BakheetPlus ratios_T0_GC_resid 0.06504543848154937\n",
      "motif_AREs_numbered_BakheetPlus ratios_T4T0_GC_resid 3.851469606761032e-12\n"
     ]
    }
   ],
   "source": [
    "#Do it out of sample so I don't have to worry about degrees of freedom for each test...\n",
    "\n",
    "\n",
    "#Minimize the squared deviations from the mean.\n",
    "def squared_deviation(f1x,f1y,f2x,f2y,f3x,f3y,f4x,f4y):\n",
    "    running_deviation = 0\n",
    "    for i in range(1,25):\n",
    "        f1x = np.array(f1x)\n",
    "        f1y = np.array(f1y)\n",
    "        f2x = np.array(f2x)\n",
    "        f2y = np.array(f2y)\n",
    "        f3x = np.array(f3x)\n",
    "        f3y = np.array(f3y)\n",
    "        f4x = np.array(f4x)\n",
    "        f4y = np.array(f4y)        \n",
    "\n",
    "        y_vals = f1y[f1x==i]\n",
    "        y_vals = np.append(y_vals,f2y[f2x==i])\n",
    "        y_vals = np.append(y_vals,f3y[f3x==i])\n",
    "        y_vals = np.append(y_vals,f4y[f4x==i])\n",
    "        if len(y_vals)>1:\n",
    "            running_deviation += np.var(y_vals)*len(y_vals)\n",
    "    return running_deviation\n",
    "\n",
    "rangemin = 5\n",
    "rangemax = 22\n",
    "\n",
    "for are_category in ['parent_motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')]\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')]\n",
    "            train_df.index = train_df.ids\n",
    "            test_df.index = test_df.ids\n",
    "            \n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "                        \n",
    "        Bakheet_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "\n",
    "            \n",
    "\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')] #it had iscontrol==1 above\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.top_ARE_deleted==1)&(referenceDF.hap=='mutated_ARE')]\n",
    "\n",
    "            train_df.index = train_df.ids\n",
    "            test_df.index = test_df.ids\n",
    "\n",
    "            def offset_dev(offset):\n",
    "                referenceDF_inUse = train_df.copy()\n",
    "                registration=0\n",
    "                f0x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f0y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=1\n",
    "                f1x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f1y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=2\n",
    "                f2x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f2y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=3\n",
    "                f3x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f3y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                return squared_deviation(f0x,f0y,f1x,f1y,f2x,f2y,f3x,f3y)\n",
    "\n",
    "            aaa = minimize(offset_dev,.001)\n",
    "            shift = aaa.x[0]\n",
    "\n",
    "            predictions_dict = {}\n",
    "\n",
    "            for parent_effective_perfect_length in range(rangemin,rangemax):\n",
    "                predictions_dict[parent_effective_perfect_length]=np.mean(train_df[figure_of_merit][train_df.parent_effective_perfect_length==parent_effective_perfect_length]+shift*train_df.parent_ARE_registration_perfect[train_df.parent_effective_perfect_length==parent_effective_perfect_length])\n",
    "\n",
    "            for parent_effective_perfect_length,test_fom,parent_ARE_registration_perfect in zip(test_df.parent_effective_perfect_length,test_df[figure_of_merit],test_df.parent_ARE_registration_perfect):\n",
    "                if parent_effective_perfect_length<rangemax:\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[parent_effective_perfect_length]-shift*parent_ARE_registration_perfect)\n",
    "                        test_actual.append(test_fom)\n",
    "\n",
    "\n",
    "\n",
    "        David_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "                        \n",
    "                        \n",
    "        statistic,pvalue = st.mannwhitneyu(Bakheet_resids**2,David_resids**2)\n",
    "        print(are_category, figure_of_merit, pvalue)\n",
    "        \n",
    "for are_category in ['motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)&(referenceDF.iscontrol==1)]\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)&(referenceDF.iscontrol==1)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "                        \n",
    "        Bakheet_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "            \n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF.chrom_number.unique():\n",
    "            train_df = referenceDF[(referenceDF.chrom_number!=chrom)] #it had iscontrol==1 above\n",
    "            test_df = referenceDF[(referenceDF.chrom_number==chrom)]\n",
    "\n",
    "            train_df.index = train_df.ids\n",
    "            test_df.index = test_df.ids\n",
    "\n",
    "            def offset_dev(offset):\n",
    "                referenceDF_inUse = train_df.copy()\n",
    "                registration=0\n",
    "                f0x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f0y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=1\n",
    "                f1x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f1y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=2\n",
    "                f2x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f2y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=3\n",
    "                f3x = referenceDF_inUse.parent_ARE_length_perfect[referenceDF_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f3y = referenceDF_inUse[figure_of_merit][referenceDF_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                return squared_deviation(f0x,f0y,f1x,f1y,f2x,f2y,f3x,f3y)\n",
    "\n",
    "            aaa = minimize(offset_dev,.001)\n",
    "            shift = aaa.x[0]\n",
    "\n",
    "\n",
    "            predictions_dict = {}\n",
    "\n",
    "            for effective_perfect_length in range(rangemin,rangemax):\n",
    "                predictions_dict[effective_perfect_length]=np.mean(train_df[figure_of_merit][train_df.effective_perfect_length==effective_perfect_length]-shift*train_df.ARE_registration_perfect[train_df.effective_perfect_length==effective_perfect_length])\n",
    "\n",
    "            for effective_perfect_length,test_fom,ARE_registration_perfect in zip(test_df.effective_perfect_length,test_df[figure_of_merit],test_df.ARE_registration_perfect):\n",
    "                if effective_perfect_length<rangemax:\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[effective_perfect_length]+shift*ARE_registration_perfect)\n",
    "                        test_actual.append(test_fom)\n",
    "\n",
    "\n",
    "                        \n",
    "        David_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "        statistic,pvalue = st.mannwhitneyu(Bakheet_resids**2,David_resids**2)\n",
    "        print(are_category, figure_of_merit, pvalue)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Do This All Again For Log-Ratios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the CXCL7 padding sequences have AREs -- we can account for these if desired...\n",
    "\n",
    "cxcl7_list = ['SUPV3L1|10:70968792-70968830','TRPT1|11:63991271-63991346','ART4|12:14982266-14982303','POLE2|14:50116899-50116969','NMRAL1|16:4511716-4511779','ADPRM|17:10614462-10614520','NUP85|17:73231775-73231829','PPP1R15A|19:49379231-49379294','PQLC3|2:11300834-11300874','FASTKD1|2:170386287-170386333','TFPI|2:188343337-188343401','YBEY|21:47717549-47717616','ALG1L|3:125648118-125648193','HELQ|4:84328529-84328604','TMEM171|5:72427558-72427617','IL4|5:132018280-132018347','PCDHA11|5:140251122-140251185','PCDHA12|5:140257437-140257474','GIN1|5:102423545-102423600','HLA-DQA1|6:32610542-32610561','CCDC132|7:92905660-92905721','NAPRT|8:144656955-144657006']\n",
    "CXCL7_ARE_list = []\n",
    "for region in referenceDF_logratio.region:\n",
    "    if region in cxcl7_list:\n",
    "        CXCL7_ARE_list.append(1)\n",
    "    else:\n",
    "        CXCL7_ARE_list.append(0)\n",
    "referenceDF_logratio['CXCL7_ARE']=CXCL7_ARE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_number = []\n",
    "for region in referenceDF_logratio.region:\n",
    "    if not pd.isnull(region):\n",
    "        chrom_number.append(region.split('|')[1].split(':')[0])\n",
    "    else:\n",
    "        chrom_number.append(np.nan)\n",
    "referenceDF_logratio['chrom_number']=chrom_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARED-Plus Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T0_GC_resid 0.12219426353873165\n",
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T4T0_GC_resid 0.30563617833484474\n",
      "motif_AREs_numbered_BakheetPlus ratios_T0_GC_resid 0.07155643391110716\n",
      "motif_AREs_numbered_BakheetPlus ratios_T4T0_GC_resid 0.24702946365276734\n"
     ]
    }
   ],
   "source": [
    "# Accounts for CXCL7:\n",
    "\n",
    "for are_category in ['parent_motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.nanmedian(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])\n",
    "        \n",
    "for are_category in ['motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.iscontrol==1)&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.iscontrol==1)&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.nanmedian(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make \"effective perfect length\" variable from length and registration:\n",
    "referenceDF_logratio['effective_perfect_length'] = referenceDF_logratio.ARE_registration_perfect + referenceDF_logratio.ARE_length_perfect\n",
    "\n",
    "\n",
    "# It helps to make a \"parent effective perfect length\" variable:\n",
    "referenceDF_logratio_byOligo = referenceDF_logratio.copy()\n",
    "referenceDF_logratio_byOligo.index = referenceDF_logratio_byOligo.ids\n",
    "parent_effective_perfect_length_list = []\n",
    "for parent_oligo in referenceDF_logratio_byOligo.parent_control_oligo:\n",
    "    if parent_oligo in referenceDF_logratio_byOligo.ids.values:\n",
    "        parent_effective_perfect_length_list.append(referenceDF_logratio_byOligo.loc[parent_oligo,'effective_perfect_length'])\n",
    "    else:\n",
    "        parent_effective_perfect_length_list.append(np.nan)\n",
    "referenceDF_logratio['parent_effective_perfect_length'] = parent_effective_perfect_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect_size_T0_GC_resid 0.1472346682873706\n",
      "effect_size_T4T0_GC_resid 0.3867410118526146\n",
      "ratios_T0_GC_resid 0.13692621237606908\n",
      "ratios_T4T0_GC_resid 0.32030577499138385\n"
     ]
    }
   ],
   "source": [
    "#Account for CXCL7:\n",
    "\n",
    "for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "#     are_category = 'parent_ARE'\n",
    "#     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "    test_predictions = []\n",
    "    test_actual = []\n",
    "    for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "        train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')&(referenceDF_logratio.CXCL7_ARE==0)] #it had iscontrol==1 above\n",
    "        test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "\n",
    "        train_df.index = train_df.ids\n",
    "        test_df.index = test_df.ids\n",
    "        \n",
    "        predictions_dict = {}\n",
    "        \n",
    "        for parent_effective_perfect_length in range(5,22):\n",
    "            predictions_dict[parent_effective_perfect_length]=np.mean(train_df[figure_of_merit][train_df.parent_effective_perfect_length==parent_effective_perfect_length])\n",
    "        \n",
    "        for parent_effective_perfect_length,test_fom in zip(test_df.parent_effective_perfect_length,test_df[figure_of_merit]):\n",
    "            if parent_effective_perfect_length<22:\n",
    "                if not pd.isnull(test_fom):\n",
    "                    test_predictions.append(predictions_dict[parent_effective_perfect_length])\n",
    "                    test_actual.append(test_fom)\n",
    "\n",
    "    print(figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])\n",
    "\n",
    "\n",
    "\n",
    "for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "#     are_category = 'parent_ARE'\n",
    "#     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "    test_predictions = []\n",
    "    test_actual = []\n",
    "    for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "        train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.CXCL7_ARE==0)] #it had iscontrol==1 above\n",
    "        test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "\n",
    "        train_df.index = train_df.ids\n",
    "        test_df.index = test_df.ids\n",
    "        \n",
    "        predictions_dict = {}\n",
    "        \n",
    "        for effective_perfect_length in range(5,22):\n",
    "            mask = train_df.effective_perfect_length==effective_perfect_length\n",
    "            mask = mask.fillna(False)\n",
    "            predictions_dict[effective_perfect_length]=np.mean(train_df[figure_of_merit][mask])\n",
    "        \n",
    "        for effective_perfect_length,test_fom in zip(test_df.effective_perfect_length,test_df[figure_of_merit]):\n",
    "            if not pd.isnull(effective_perfect_length):\n",
    "                if effective_perfect_length<22:\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[effective_perfect_length])\n",
    "                        test_actual.append(test_fom)\n",
    "\n",
    "    print(figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Effective Length Pentamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groups: 5, 6-9, 10-13, 14-17, 18-21 (effective length).  Add one for imperfect?\n",
    "david_groups_perfect = []\n",
    "for effective_perfect_length in referenceDF_logratio.effective_perfect_length:\n",
    "    if not pd.isnull(effective_perfect_length):\n",
    "        if effective_perfect_length<=5:\n",
    "            david_groups_perfect.append(1)\n",
    "        elif effective_perfect_length<=9:\n",
    "            david_groups_perfect.append(2)\n",
    "        elif effective_perfect_length<=13:\n",
    "            david_groups_perfect.append(3)\n",
    "        elif effective_perfect_length<=17:\n",
    "            david_groups_perfect.append(4)\n",
    "        elif effective_perfect_length<=22:\n",
    "            david_groups_perfect.append(5)\n",
    "        elif effective_perfect_length>22:\n",
    "            david_groups_perfect.append(6)\n",
    "        else:\n",
    "            david_groups_perfect.append(np.nan)\n",
    "    else:\n",
    "        david_groups_perfect.append(np.nan)\n",
    "referenceDF_logratio['david_groups_perfect']=david_groups_perfect\n",
    "\n",
    "parent_david_groups_perfect = []\n",
    "referenceDF_logratio_byOligo = referenceDF_logratio.copy()\n",
    "referenceDF_logratio_byOligo.index = referenceDF_logratio.ids\n",
    "for oligo,parent_oligo in zip(referenceDF_logratio.ids.values,referenceDF_logratio.parent_control_oligo.values):\n",
    "    if not pd.isnull(parent_oligo):\n",
    "        parent_david_groups_perfect.append(referenceDF_logratio_byOligo.loc[parent_oligo,'david_groups_perfect'])\n",
    "    else:\n",
    "        parent_david_groups_perfect.append(np.nan)\n",
    "        \n",
    "referenceDF_logratio['parent_david_groups_perfect']=parent_david_groups_perfect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_david_groups_perfect effect_size_T0_GC_resid 0.14471975732036033\n",
      "parent_david_groups_perfect effect_size_T4T0_GC_resid 0.3621910843279327\n",
      "david_groups_perfect ratios_T0_GC_resid 0.10716883090969442\n",
      "david_groups_perfect ratios_T4T0_GC_resid 0.30679478908547325\n"
     ]
    }
   ],
   "source": [
    "#Account for CXCL7\n",
    "\n",
    "for are_category in ['parent_david_groups_perfect']:\n",
    "    for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category > 1)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category>1)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])\n",
    "        \n",
    "for are_category in ['david_groups_perfect']:\n",
    "    for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.iscontrol==1)&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.iscontrol==1)&(referenceDF_logratio.CXCL7_ARE==0)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category > 1)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category > 1)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "        print(are_category, figure_of_merit, np.corrcoef(test_predictions,test_actual)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann Whitney U Test For Significance of Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps to make a \"parent_ARE_length_perfect\" and a \"parent_ARE_registration_perfect\" variable:\n",
    "referenceDF_logratio_byOligo = referenceDF_logratio.copy()\n",
    "referenceDF_logratio_byOligo.index = referenceDF_logratio_byOligo.ids\n",
    "parent_ARE_length_perfect_list = []\n",
    "parent_ARE_registration_perfect_list = []\n",
    "for parent_oligo in referenceDF_logratio_byOligo.parent_control_oligo:\n",
    "    if parent_oligo in referenceDF_logratio_byOligo.ids.values:\n",
    "        parent_ARE_length_perfect_list.append(referenceDF_logratio_byOligo.loc[parent_oligo,'ARE_length_perfect'])\n",
    "        parent_ARE_registration_perfect_list.append(referenceDF_logratio_byOligo.loc[parent_oligo,'ARE_registration_perfect'])\n",
    "    else:\n",
    "        parent_ARE_length_perfect_list.append(np.nan)\n",
    "        parent_ARE_registration_perfect_list.append(np.nan)\n",
    "referenceDF_logratio['parent_ARE_length_perfect'] = parent_ARE_length_perfect_list\n",
    "referenceDF_logratio['parent_ARE_registration_perfect'] = parent_ARE_registration_perfect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T0_GC_resid 0.33277665459891315\n",
      "parent_motif_AREs_numbered_BakheetPlus effect_size_T4T0_GC_resid 0.0013465789645256332\n",
      "motif_AREs_numbered_BakheetPlus ratios_T0_GC_resid 0.006796850275162462\n",
      "motif_AREs_numbered_BakheetPlus ratios_T4T0_GC_resid 0.005655734532549821\n"
     ]
    }
   ],
   "source": [
    "#Do it out of sample so I don't have to worry about degrees of freedom for each test...\n",
    "\n",
    "\n",
    "#Minimize the squared deviations from the mean.\n",
    "def squared_deviation(f1x,f1y,f2x,f2y,f3x,f3y,f4x,f4y):\n",
    "    running_deviation = 0\n",
    "    for i in range(1,25):\n",
    "        f1x = np.array(f1x)\n",
    "        f1y = np.array(f1y)\n",
    "        f2x = np.array(f2x)\n",
    "        f2y = np.array(f2y)\n",
    "        f3x = np.array(f3x)\n",
    "        f3y = np.array(f3y)\n",
    "        f4x = np.array(f4x)\n",
    "        f4y = np.array(f4y)        \n",
    "\n",
    "        y_vals = f1y[f1x==i]\n",
    "        y_vals = np.append(y_vals,f2y[f2x==i])\n",
    "        y_vals = np.append(y_vals,f3y[f3x==i])\n",
    "        y_vals = np.append(y_vals,f4y[f4x==i])\n",
    "        if len(y_vals)>1:\n",
    "            running_deviation += np.var(y_vals)*len(y_vals)\n",
    "    return running_deviation\n",
    "\n",
    "rangemin = 5\n",
    "rangemax = 22\n",
    "\n",
    "for are_category in ['parent_motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['effect_size_T0_GC_resid','effect_size_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')]\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')]\n",
    "            train_df.index = train_df.ids\n",
    "            test_df.index = test_df.ids\n",
    "            \n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "                        \n",
    "        Bakheet_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "\n",
    "            \n",
    "\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')] #it had iscontrol==1 above\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.top_ARE_deleted==1)&(referenceDF_logratio.hap=='mutated_ARE')]\n",
    "\n",
    "            train_df.index = train_df.ids\n",
    "            test_df.index = test_df.ids\n",
    "\n",
    "            def offset_dev(offset):\n",
    "                referenceDF_logratio_inUse = train_df.copy()\n",
    "                registration=0\n",
    "                f0x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f0y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=1\n",
    "                f1x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f1y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=2\n",
    "                f2x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f2y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=3\n",
    "                f3x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f3y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                return squared_deviation(f0x,f0y,f1x,f1y,f2x,f2y,f3x,f3y)\n",
    "\n",
    "            aaa = minimize(offset_dev,.001)\n",
    "            shift = aaa.x[0]\n",
    "\n",
    "            predictions_dict = {}\n",
    "\n",
    "            for parent_effective_perfect_length in range(rangemin,rangemax):\n",
    "                predictions_dict[parent_effective_perfect_length]=np.mean(train_df[figure_of_merit][train_df.parent_effective_perfect_length==parent_effective_perfect_length]+shift*train_df.parent_ARE_registration_perfect[train_df.parent_effective_perfect_length==parent_effective_perfect_length])\n",
    "\n",
    "            for parent_effective_perfect_length,test_fom,parent_ARE_registration_perfect in zip(test_df.parent_effective_perfect_length,test_df[figure_of_merit],test_df.parent_ARE_registration_perfect):\n",
    "                if parent_effective_perfect_length<rangemax:\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[parent_effective_perfect_length]-shift*parent_ARE_registration_perfect)\n",
    "                        test_actual.append(test_fom)\n",
    "\n",
    "\n",
    "\n",
    "        David_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "                        \n",
    "                        \n",
    "        statistic,pvalue = st.mannwhitneyu(Bakheet_resids**2,David_resids**2)\n",
    "        print(are_category, figure_of_merit, pvalue)\n",
    "        \n",
    "for are_category in ['motif_AREs_numbered_BakheetPlus']:\n",
    "    for figure_of_merit in ['ratios_T0_GC_resid','ratios_T4T0_GC_resid']:\n",
    "    #     are_category = 'parent_ARE'\n",
    "    #     figure_of_merit = 'effect_size_T0_GC_resid'\n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)&(referenceDF_logratio.iscontrol==1)]\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)&(referenceDF_logratio.iscontrol==1)]\n",
    "\n",
    "            predictions_dict = {}\n",
    "            for category in train_df[are_category].unique():\n",
    "                if (category != 0)&(category<7):\n",
    "                    predictions_dict[category]=np.mean(train_df[figure_of_merit][train_df[are_category]==category])\n",
    "\n",
    "            for test_category,test_fom in zip(test_df[are_category],test_df[figure_of_merit]):\n",
    "                if (test_category!=0)&(test_category<7):\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[test_category])\n",
    "                        test_actual.append(test_fom)\n",
    "                        \n",
    "        Bakheet_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "            \n",
    "        test_predictions = []\n",
    "        test_actual = []\n",
    "        for chrom in referenceDF_logratio.chrom_number.unique():\n",
    "            train_df = referenceDF_logratio[(referenceDF_logratio.chrom_number!=chrom)] #it had iscontrol==1 above\n",
    "            test_df = referenceDF_logratio[(referenceDF_logratio.chrom_number==chrom)]\n",
    "\n",
    "            train_df.index = train_df.ids\n",
    "            test_df.index = test_df.ids\n",
    "\n",
    "            def offset_dev(offset):\n",
    "                referenceDF_logratio_inUse = train_df.copy()\n",
    "                registration=0\n",
    "                f0x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f0y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=1\n",
    "                f1x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f1y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=2\n",
    "                f2x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f2y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                registration=3\n",
    "                f3x = referenceDF_logratio_inUse.parent_ARE_length_perfect[referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+registration\n",
    "                f3y = referenceDF_logratio_inUse[figure_of_merit][referenceDF_logratio_inUse.parent_ARE_registration_perfect==registration]+offset*registration\n",
    "                return squared_deviation(f0x,f0y,f1x,f1y,f2x,f2y,f3x,f3y)\n",
    "\n",
    "            aaa = minimize(offset_dev,.001)\n",
    "            shift = aaa.x[0]\n",
    "\n",
    "\n",
    "            predictions_dict = {}\n",
    "\n",
    "            for effective_perfect_length in range(rangemin,rangemax):\n",
    "                predictions_dict[effective_perfect_length]=np.mean(train_df[figure_of_merit][train_df.effective_perfect_length==effective_perfect_length]-shift*train_df.ARE_registration_perfect[train_df.effective_perfect_length==effective_perfect_length])\n",
    "\n",
    "            for effective_perfect_length,test_fom,ARE_registration_perfect in zip(test_df.effective_perfect_length,test_df[figure_of_merit],test_df.ARE_registration_perfect):\n",
    "                if effective_perfect_length<rangemax:\n",
    "                    if not pd.isnull(test_fom):\n",
    "                        test_predictions.append(predictions_dict[effective_perfect_length]+shift*ARE_registration_perfect)\n",
    "                        test_actual.append(test_fom)\n",
    "\n",
    "\n",
    "                        \n",
    "        David_resids = np.array(test_predictions)-np.array(test_actual)\n",
    "        statistic,pvalue = st.mannwhitneyu(Bakheet_resids**2,David_resids**2)\n",
    "        print(are_category, figure_of_merit, pvalue)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "241px",
    "left": "1292px",
    "right": "235px",
    "top": "117px",
    "width": "393px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
